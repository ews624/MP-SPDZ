import math
import mpc_math

sfix.set_precision(16,32)
rows = 14
columns = 4
## NOTE: DATA columns in order from left to right are
# Color, Outline, Dot, Shape
# 0,     1,        2,   3

#Color green =1 , yellow = 2, red =3

class Tree:
	def __init__(self):
		self.left = None
		self.center = None
		self.right = None
		self.attribute = None
		self.data = None

def get_Entropy(CombinedInputs,column_number,range):
	value_tracking_array = Array(5,sfix)
	value_tracking_array.assign_all(0)
	lastint = sint(0)
	skip = 0
	shape_array = Array(3,sfix)
	shape_array.assign_all(0)

    #I am doing some cheating here, knowing that we have only 3 unique values for our dataset
    #I am just going to get track of them inidivually and hopefully it will be readable
	onevar = sint.MemValue(0)
	twovar = sint.MemValue(0)
	threevar = sint.MemValue(0)

    #Cheating again, here we are keeping track of one only shape of the at most 3 unique values
    #we will later find the amount of the other shape using subtraction
	oneshape = sint.MemValue(0)
	twoshape = sint.MemValue(0)
	threeshape = sint.MemValue(0)


	unique_vales = sint.MemValue(1)
	@for_range_opt(range)
	def f(i):
		compvar = CombinedInputs[i][column_number]
		shape_value = CombinedInputs[i][3]
		lastint = (shape_value == sint(1))

        #Since we are only checking for upto 3 unique values we only need to compare upto 3 possibilities

		f = (compvar == sint(1))
		onevar.write(((onevar+1)*f)+  ((sint(1)-f)*onevar))
		oneshape.write(((oneshape+lastint)*f)+  ((sint(1)-f)*oneshape))
		f = (compvar == sint(2))
		twovar.write(((twovar+1)*f) +((sint(1)-f)*twovar))
		twoshape.write(((twoshape+lastint)*f) +((sint(1)-f)*twoshape))
		f = (compvar == sint(3))
		threevar.write(((threevar+1)*f)+((sint(1)-f)*threevar))
		threeshape.write(((threeshape+lastint)*f)+((sint(1)-f)*threeshape))
		f = (unique_vales < compvar)
		unique_vales.write((compvar*f)+(unique_vales*(sint(1)-f)))

        #This fixes a bug with the program
        #I don't understand but this fixes it
		if((sint(0) < sint(1)).reveal()):
			skip = 0


	Entropy_Array = Array(3,sfix)
	value_tracking_array[0] = onevar
	value_tracking_array[1] = twovar
	value_tracking_array[2] = threevar

	shape_array[0] = oneshape
	shape_array[1] = twoshape
	shape_array[2] = threeshape

    #this calculates the entropy based on the 3 remaining attributes
    #since we only have 2 shapes to choose from, I am cheating again with partone and parttwo
    #
	@for_range_opt(unique_vales.reveal())
	def W(i):
		denom = value_tracking_array[i]
		top = shape_array[i]
		x = top/denom
		difference = denom-top
		y = difference/denom
		partone = (x*mpc_math.log2_fx(x))
		parttwo = (y*mpc_math.log2_fx(y))
		Entropy_Array[i] = (-partone)+(-parttwo)

	return Entropy_Array

def gainChecker(squares,triangles,totalofColor,root,CombinedInputs,ColorInt,totalRows,color_Entropy):

	###Need to refactoring
	### Name Clean up and commenting
	latestEntro = sfix.MemValue(0.0)
	print_ln('in gainchecker num of squares is %s,triangles %s',squares.reveal(),triangles.reveal())

	root.left = Tree()
	root.right = Tree()

	squares = sfix(squares)
	triangles = sfix(triangles)
	totalofColor = sfix(totalofColor)
	x = sfix(squares/totalofColor)
	y = sfix(triangles/totalofColor)
	latestEntro = (-(x*mpc_math.log2_fx(x))-(y*(mpc_math.log2_fx(y))))
	print_ln('latestEntro is %s',latestEntro.reveal())
	totaldots = sint.MemValue(0)
	totalundotted = sint.MemValue(0)
	totaldashed = sint.MemValue(0)
	totalundashed = sint.MemValue(0)
	total = sfix.MemValue(0)
	color = sint(ColorInt)

	dashedTri = sint.MemValue(0)
	solidTri = sint.MemValue(0)
	dottedTri = sint.MemValue(0)
	undotTri = sint.MemValue(0)
	totalTri = sint.MemValue(0)

	dashedSqu = sint.MemValue(0)
	solidSqu = sint.MemValue(0)
	dottedSqu = sint.MemValue(0)
	undotSqu = sint.MemValue(0)
	totalSqu = sint.MemValue(0)
	#create deeper nodes
	@for_range_opt(totalRows)
	def _(i):

		colorCheck = (CombinedInputs[i][0]== color)
		triCheck = (CombinedInputs[i][3] == sint(1))
		totalTri.write(totalTri+(colorCheck*triCheck))
		totalSqu.write(totalSqu+(colorCheck*(sint(1)-triCheck)))

		f = (sint(1)==CombinedInputs[i][2])
		dottedTri.write(dottedTri+(colorCheck*f*triCheck))
		dottedSqu.write(dottedSqu+(colorCheck*f*(sint(1)-triCheck)))

		undotTri.write(undotTri+(colorCheck*(sint(1)-f)*triCheck))
		undotSqu.write(undotSqu+(colorCheck*(sint(1)-f)*(sint(1)-triCheck)))

		da = (sint(1)==CombinedInputs[i][1])
		dashedTri.write(dashedTri+(colorCheck*da*triCheck))
		dashedSqu.write(dashedSqu+(colorCheck*(sint(1)-triCheck)*da))

		solidTri.write(solidTri+(colorCheck*(sint(1)-da)*triCheck))
		solidSqu.write(solidSqu+(colorCheck*(sint(1)-da)*(sint(1)-triCheck)))


		f = (sint(1)==CombinedInputs[i][2])
		l = (f*colorCheck)
		totaldots.write(totaldots+l)
		l = (sint(1)-f)*colorCheck
		totalundotted.write(totalundotted+l)

		f = (sint(1)==CombinedInputs[i][1])
		l = (f*colorCheck)
		totaldashed.write(totaldashed+l)
		f = (sint(1)-f)*colorCheck
		totalundashed.write(totalundashed+f)

		total.write(total+colorCheck)


	outlineTri = sfix(dashedTri)
	outlineTotal = sfix(dashedTri+dashedSqu)
	outlineSqu = sfix(dashedSqu)

	x = sfix(outlineTri/outlineTotal)
	y = sfix(outlineSqu/outlineTotal)

	partone = -(x*mpc_math.log2_fx(x))
	parttwo = -(y*mpc_math.log2_fx(y))

	completed = sfix(partone+parttwo)
	completed = completed *sfix(sfix(sfix(outlineTotal)/sfix(total)))
	entroOne = sfix(completed)

	print_ln('outline tri is %s, outline total is %s',outlineTri.reveal(),outlineTotal.reveal())
	###
	####Need to do the second part of entropy checking
	###


	solidTotal = sfix(sfix(solidSqu)+sfix(solidTri))

	x = sfix(solidTri)/sfix(solidTotal)
	y = sfix(solidSqu)/sfix(solidTotal)

	partone = -(x*mpc_math.log2_fx(x))
	parttwo = -(y*mpc_math.log2_fx(y))

	completed = sfix(partone+parttwo)
	completed = completed * sfix(sfix(sfix(solidTotal)/sfix(total)))


	entroOne = entroOne+ completed
	print_ln('entroOne is %s',entroOne.reveal())
	print_ln('partone is %s and parttwo is %s',partone.reveal(),parttwo.reveal())
	totalItems = totalTri + totalSqu
	allSolid = solidTri + solidSqu
	allDashed = dashedSqu + dashedTri
	print_ln('total items is %s and allsolids is %s',totalItems.reveal(),allSolid.reveal())
	print_ln('all dashed is %s',allDashed.reveal())



	dottedX = sfix(dottedTri)
	dottedBot = sfix(dottedTri+dottedSqu)
	dottedY = sfix(dottedSqu)
	x =sfix(dottedX/dottedBot)
	y = sfix(dottedY/dottedBot)
	partone = -(x*mpc_math.log2_fx(x))
	parttwo = -(y*mpc_math.log2_fx(y))
	entrotwo = (partone+parttwo)
	print_ln('dotted tri"s is %s, dotted square is %s',dottedX.reveal(),dottedY.reveal())
	entrotwo = sfix(entrotwo*sfix(sfix(dottedBot)/sfix(total)))
	undotX = sfix(undotTri)
	undotBot = sfix(undotTri+undotSqu)
	undotY = sfix(undotSqu)
	x =sfix(undotX/undotBot)
	y = sfix(undotY/undotBot)
	partone = -(x*mpc_math.log2_fx(x))
	parttwo = -(y*mpc_math.log2_fx(y))
	entrotwo = entrotwo + (sfix(undotBot)/sfix(total)*(sfix(partone)+sfix(parttwo)))
	print_ln('entrotwo is %s',entrotwo.reveal())
	print_ln('partone is %s and parttwo is %s',partone.reveal(),parttwo.reveal())




	gainOne = sfix(color_Entropy[ColorInt-1] - entroOne)
	gainTwo = sfix(color_Entropy[ColorInt-1] - entrotwo)


	###Fix, need to build tree by biggest gain
	### all this does is track the gains
	f = (gainOne > gainTwo)
	mover = ((f*gainOne)+(gainTwo*(1-f)))
	root.left.data = mover.reveal()
	mover = (((1-f)*gainOne)+(f*gainTwo))
	root.right.data = mover.reveal()

def get_Next_layer(CombinedInputs,color_Entropy,totalRows,ColorInt,root):
	#THIS whole process needs a better way to be done!!!!
	#
	#ColorInt is just the integar value for the colors in the CombinedInputs array

	###
	###
	###Function needs commenting
	###
	###
	print_ln('')

	#yellow = 2
	#green = 1
	#red = 3
	squares = sint.MemValue(0)
	triangles = sint.MemValue(0)
	totalcolor = sint.MemValue(0)

	@for_range_opt(totalRows)
	def _(j):
		color_comparison = (ColorInt ==CombinedInputs[j][0])
		totalcolor.write(((totalcolor+1)*color_comparison)+(totalcolor*(sint(1)-color_comparison)))
		square = (sint(2) == CombinedInputs[j][3])
		squares.write(squares + (color_comparison*square))
		triangle = (sint(1) == CombinedInputs[j][3])
		triangles.write(triangles+(triangle*color_comparison))

	gainChecker(squares,triangles,totalcolor,root,CombinedInputs,ColorInt,totalRows,color_Entropy)




def get_Color_Entropy(CombinedInputs,heuristic_column,range):
	print_ln('Tree Building')
	Entropy_Array = Array(3,sfix)
	Entropy_Array = get_Entropy(CombinedInputs,heuristic_column,range)
	print_ln()
	print_ln()
	print_ln('The entropy for the color green is %s',Entropy_Array[0].reveal())
	print_ln('The entropy for the color yellow is %s',Entropy_Array[1].reveal())
	print_ln('The entropy for the color red is %s',Entropy_Array[2].reveal())

	return Entropy_Array

def generateArray(rows,columns):

    p0_inputs = sint.Matrix(rows,columns)
    p0_inputs.input_from(0)

    p1_inputs = sint.Matrix(rows,columns)
    p1_inputs.input_from(1)

    p2_inputs = sint.Matrix(rows,columns)
    p2_inputs.input_from(2)
    #Large Array
    shamir_input = sint.Matrix((3*rows),columns)

    @for_range_parallel(3,[rows,columns])
    def hi(i,j):
    	shamir_input[i][j] = p0_inputs[i][j]
    	shamir_input[i+rows][j] = p1_inputs[i][j]
    	shamir_input[i+(rows*2)][j] = p2_inputs[i][j]
    return shamir_input

def first_entropy(CombinedInputs, shapeIndex,totalRows):
    entropy = sfix.MemValue(0)
    triangles = sint.MemValue(0)
    squares = sint.MemValue(0)
    @for_range_opt(totalRows)
    def f(i):
        #Load in value from InputArray
        compvar = CombinedInputs[i][shapeIndex]
		#sint(1) is the value for triangles in the dataset
        f = (compvar == sint(1))
        triangles.write(triangles+f)
        squares.write(squares+(sint(1)-f))

    x = sfix(sfix(triangles)/sfix(totalRows))
    y = sfix(squares)/sfix(totalRows)
    entropy.write((-x*(mpc_math.log2_fx(x)))+(-y*(mpc_math.log2_fx(y))))

    return entropy

#Slide 19
#This calculates the gain which is the Entropy of the shapes minus whatever entropy attribute we are comparing
def get_gain(EntroValue,unique_vales,Comparison_Entropy,value_tracking_array,range):
	sum_of_Entro = sfix.MemValue(0.0)
	@for_range_opt(unique_vales)
	def tr(i):
		sum_of_Entro.write(((value_tracking_array[i]/range)*EntroValue[i])+ sum_of_Entro)
	gain = Comparison_Entropy - sfix(sum_of_Entro)
	return gain

def attribute_gain(CombinedInputs,Comparison_Entropy,column_number,range):
	Entropy_Array = Array(3,sfix)
	value_tracking_array = Array(5,sfix)
	value_tracking_array.assign_all(0)
	lastint = sint(0)
	skip = 0
	shape_array = Array(3,sfix)
	shape_array.assign_all(0)

    #I am doing some cheating here, knowing that we have only 3 unique values for our dataset
    #I am just going to get track of them inidivually and hopefully it will be readable
	onevar = sint.MemValue(0)
	twovar = sint.MemValue(0)
	threevar = sint.MemValue(0)

    #Cheating again, here we are keeping track of one only shape of the at most 3 unique values
    #we will later find the amount of the other shape using subtraction
	oneshape = sint.MemValue(0)
	twoshape = sint.MemValue(0)
	threeshape = sint.MemValue(0)

	gain = sfix(0.0)
	unique_vales = sint.MemValue(1)
	@for_range_opt(range)
	def f(i):
		compvar = CombinedInputs[i][column_number]
		shape_value = CombinedInputs[i][3]
		lastint = (shape_value == sint(1))

        #Since we are only checking for upto 3 unique values we only need to compare upto 3 possibilities

		f = (compvar == sint(1))
		onevar.write(((onevar+1)*f)+  ((sint(1)-f)*onevar))
		oneshape.write(((oneshape+lastint)*f)+  ((sint(1)-f)*oneshape))
		f = (compvar == sint(2))
		twovar.write(((twovar+1)*f) +((sint(1)-f)*twovar))
		twoshape.write(((twoshape+lastint)*f) +((sint(1)-f)*twoshape))
		f = (compvar == sint(3))
		threevar.write(((threevar+1)*f)+((sint(1)-f)*threevar))
		threeshape.write(((threeshape+lastint)*f)+((sint(1)-f)*threeshape))

		f = (unique_vales < compvar)
		unique_vales.write((compvar*f)+(unique_vales*(sint(1)-f)))

        #This fixes a bug with the program
        #I don't understand but this fixes it
		if((sint(0) < sint(1)).reveal()):
			skip = 0



	value_tracking_array[0] = onevar
	value_tracking_array[1] = twovar
	value_tracking_array[2] = threevar

	shape_array[0] = oneshape
	shape_array[1] = twoshape
	shape_array[2] = threeshape

    #this calculates the entropy based on the 3 remaining attributes
    #since we only have 2 shapes to choose from, I am cheating again with partone and parttwo
    #
	@for_range_opt(unique_vales.reveal())
	def W(i):
		denom = value_tracking_array[i]
		top = shape_array[i]
		x = top/denom
		difference = denom-top
		y = difference/denom
		partone = (x*mpc_math.log2_fx(x))
		parttwo = (y*mpc_math.log2_fx(y))
		Entropy_Array[i] = (-partone)+(-parttwo)

	gain = get_gain(Entropy_Array,unique_vales.reveal(),Comparison_Entropy,value_tracking_array,range)
    #print_ln('Gain is %s',gain.reveal())
	return gain

#Combine all 3 parties inputs into 1 single array for ease of use
CombinedInputs = generateArray(rows,columns)
totalRows = rows*3

Shape_Entropy = sfix(0.0)
#calculate the Entropy of the Shape Attirbute
#3 is used at the second parameter because that is the column index for the shape attribute
Shape_Entropy = first_entropy(CombinedInputs,3,totalRows)
print_ln('Entropy of the Shape attribute is %s', Shape_Entropy.reveal())
print_ln()
print_ln()

gain_array = Array(3,sfix)
@for_range_opt(3)
def gainAll(i):
	gain_array[i]= attribute_gain(CombinedInputs,Shape_Entropy,i,totalRows)

print_ln("The Color attribute has a gain of %s", gain_array[0].reveal())
print_ln("The Outline attribute has a gain of %s", gain_array[1].reveal())
print_ln("The Dot attribute has a gain of %s", gain_array[2].reveal())
print_ln()
print_ln()

f = sint(-1)
largestGain = sfix.MemValue(0.0)
maxindex = sint.MemValue(0)
@for_range_opt(3)
def _(i):
	f = (largestGain < gain_array[i])
	maxindex.write((f*i)+ (maxindex*(sint(1)-f)))
	largestGain.write((gain_array[i]*f)+ (largestGain*(sint(1)-f)))
print_ln('largest gain index is %s which is %s',maxindex.reveal(),gain_array[maxindex.reveal()].reveal())
print_ln()
print_ln()
#For tree building our first layer has been determine from the attribute with the largest gain
#once we divide all inputs by color then we have to find the gain for outline and dot for each indivual color
#
color_Entropy = Array(3,sfix)
color_Entropy = get_Color_Entropy(CombinedInputs,maxindex.reveal(),totalRows)
print_ln()
print_ln()
root = Tree()
root.data = 'Color'
root.left = Tree()
root.center = Tree()
root.right = Tree()

root.center.Attirbute = "Green"
get_Next_layer(CombinedInputs,color_Entropy,totalRows,1,root.center)

root.left.Attirbute = "Yellow"
get_Next_layer(CombinedInputs,color_Entropy,totalRows,2,root.left)

root.right.attribute = "Red"
get_Next_layer(CombinedInputs,color_Entropy,totalRows,3,root.right)
