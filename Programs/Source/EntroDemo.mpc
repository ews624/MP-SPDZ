import math
import mpc_math

sfix.set_precision(16,32)
rows = 14
columns = 4
## NOTE: DATA columns in order from left to right are
# Color, Outline, Dot, Shape
# 0,     1,        2,   3

#Color green =1 , yellow = 2, red =3

class Tree:
	def __init__(self):
		self.left = None
		self.center = None
		self.right = None
		self.attribute = None
		self.data = None

def get_Entropy(CombinedInputs,column_number,range):
	value_tracking_array = Array(5,sfix)
	value_tracking_array.assign_all(0)
	lastint = sint(0)
	skip = 0
	shape_array = Array(3,sfix)
	shape_array.assign_all(0)

    #I am doing some cheating here, knowing that we have only 3 unique values for our dataset
    #I am just going to get track of them inidivually and hopefully it will be readable
	onevar = sint.MemValue(0)
	twovar = sint.MemValue(0)
	threevar = sint.MemValue(0)

    #Cheating again, here we are keeping track of one only shape of the at most 3 unique values
    #we will later find the amount of the other shape using subtraction
	oneshape = sint.MemValue(0)
	twoshape = sint.MemValue(0)
	threeshape = sint.MemValue(0)


	unique_vales = sint.MemValue(1)
	@for_range_opt(range)
	def f(i):
		compvar = CombinedInputs[i][column_number]
		shape_value = CombinedInputs[i][3]
		lastint = (shape_value == sint(1))

        #Since we are only checking for upto 3 unique values we only need to compare upto 3 possibilities

		f = (compvar == sint(1))
		onevar.write(((onevar+1)*f)+  ((sint(1)-f)*onevar))
		oneshape.write(((oneshape+lastint)*f)+  ((sint(1)-f)*oneshape))
		f = (compvar == sint(2))
		twovar.write(((twovar+1)*f) +((sint(1)-f)*twovar))
		twoshape.write(((twoshape+lastint)*f) +((sint(1)-f)*twoshape))
		f = (compvar == sint(3))
		threevar.write(((threevar+1)*f)+((sint(1)-f)*threevar))
		threeshape.write(((threeshape+lastint)*f)+((sint(1)-f)*threeshape))
		f = (unique_vales < compvar)
		unique_vales.write((compvar*f)+(unique_vales*(sint(1)-f)))

        #This fixes a bug with the program
        #I don't understand but this fixes it
		if((sint(0) < sint(1)).reveal()):
			skip = 0


	Entropy_Array = Array(3,sfix)
	value_tracking_array[0] = onevar
	value_tracking_array[1] = twovar
	value_tracking_array[2] = threevar

	shape_array[0] = oneshape
	shape_array[1] = twoshape
	shape_array[2] = threeshape

    #this calculates the entropy based on the 3 remaining attributes
    #since we only have 2 shapes to choose from, I am cheating again with partone and parttwo
    #
	@for_range_opt(unique_vales.reveal())
	def W(i):
		denom = value_tracking_array[i]
		top = shape_array[i]
		x = top/denom
		difference = denom-top
		y = difference/denom
		partone = (x*mpc_math.log2_fx(x))
		parttwo = (y*mpc_math.log2_fx(y))
		Entropy_Array[i] = (-partone)+(-parttwo)

	return Entropy_Array


def get_Next_layer(CombinedInputs,color_Entropy,totalRows):
	#THIS whole process needs a better way to be done!!!!
	#Maybe create new arrays that only have a certain color in it
	print_ln('calculating Next layer')
	outline_Entropy = Array(3,sfix)
	dot_Entropy = Array(3,sfix)
	red_outline_Entropy = sfix.MemValue(0)
	red_dot_Entropy = sfix.MemValue(0)

	red_total = sint.MemValue(0)
	green_total = sint.MemValue(0)
	yellow_total = sint.MemValue(0)

	red_triangle = sint.MemValue(0)
	green_triangle = sint.MemValue(0)
	yellow_triangle = sint.MemValue(0)

	red_triangle_dot = sint.MemValue(0)
	green_triangle_dot = sint.MemValue(0)
	yellow_triangle_dot = sint.MemValue(0)

	red_outlined = sint.MemValue(0)
	green_outlined = sint.MemValue(0)
	yellow_outlined = sint.MemValue(0)

	red_triangle_outline = sint.MemValue(0)
	green_triangle_outline = sint.MemValue(0)
	yellow_triangle_outline = sint.MemValue(0)


	red_dotted = sint.MemValue(0)
	green_dotted = sint.MemValue(0)
	yellow_dotted = sint.MemValue(0)


	@for_range_opt(totalRows)
	def f(i):
		outline = CombinedInputs[i][1]
		dot = CombinedInputs[i][2]
		shape = CombinedInputs[i][3]
		color = CombinedInputs[i][0]

		#Find by color
		yellow = (color == sint(2))
		red = (color == sint(3))
		green = (color == sint(1))

		yellow_total.write(yellow_total+ yellow)
		red_total.write(red_total+red)
		green_total.write(green_total+green)



		#TODO
		#WE NEED TO DO SOMETHING LIKE RED_TRIGANLE_DOT
		#to make the code work for gain calculation



		triangle = (shape ==sint(1))
		red_triangle.write(red_triangle+(triangle*red))
		green_triangle.write(green_triangle+(triangle*green))
		yellow_triangle.write(yellow_triangle+(triangle*yellow))

		dotted = (dot == sint(1))
		red_dotted.write(red_dotted + (dotted *red))
		green_dotted.write(green_dotted+(dotted*green))
		yellow_dotted.write(yellow_dotted+(dotted*yellow))

		red_triangle_dot.write(red_triangle_dot+(triangle*red*dotted))


		outlined = (outline == sint(1))
		red_outlined.write(red_outlined+(outlined*red))
		green_outlined.write(green_outlined+(outlined*green))
		yellow_outlined.write(yellow_outlined+(outlined*yellow))

		red_triangle_outline.write(red_triangle_outline+(triangle*red*outlined))

	print_ln('Total amount of red is %s',red_total.reveal())

	#Red entropy calculates
		#outline
	x = sfix(sfix(red_outlined)/sfix(red_total))
	difference = red_total - red_outlined
	y = sfix(sfix(difference)/sfix(red_total))
	red_outline_Entropy.write((-x*(mpc_math.log2_fx(x)))+(-y*(mpc_math.log2_fx(y))))

	print_ln('Red outline entropy is %s, red outlined is %s, red triangle outline is %s',red_outline_Entropy.reveal(), red_outlined.reveal(), red_triangle_outline.reveal())

	x = sfix(red_triangle_outline)/sfix(red_outlined)
	difference = red_outlined - red_triangle_outline
	y = sfix(difference)/sfix(red_outlined)
	temp = sfix((-x*(mpc_math.log2_fx(x)))+(-y*(mpc_math.log2_fx(y))))




	print_ln('Red triangle outline entropy is %s, x is %s, y is %s',temp.reveal(), x.reveal(),y.reveal())
	red_gain = sfix(red_outline_Entropy)- sfix(temp)
	print_ln('Red triangle outline gain is %s', red_gain.reveal())
		#dotted
	x = sfix(red_dotted)/sfix(red_total)
	difference = red_total-red_dotted
	y = sfix(difference)/sfix(red_total)
	red_dot_Entropy.write((-x*(mpc_math.log2_fx(x)))+(-y*(mpc_math.log2_fx(y))))
	print_ln('Red dot entropy is %s',red_dot_Entropy.reveal())
	x = sfix(red_triangle_dot)/sfix(red_dotted)
	difference = red_dotted - red_triangle_dot
	y = sfix(difference)/sfix(red_dotted)
	temp = sfix((-x*(mpc_math.log2_fx(x)))+(-y*(mpc_math.log2_fx(y))))
	red_dot_Entropy.write(red_dot_Entropy- temp)
	print_ln('Red temp is %s Red dot gain is %s',temp.reveal(),red_dot_Entropy.reveal())
	root = Tree()


def get_Color_Entropy(CombinedInputs,heuristic_column,range):
	print_ln('Tree Building')
	Entropy_Array = Array(3,sfix)
	Entropy_Array = get_Entropy(CombinedInputs,heuristic_column,range)
	print_ln()
	print_ln()
	print_ln('The entropy for the color green is %s',Entropy_Array[0].reveal())
	print_ln('The entropy for the color yellow is %s',Entropy_Array[1].reveal())
	print_ln('The entropy for the color red is %s',Entropy_Array[2].reveal())

	return Entropy_Array

def generateArray(rows,columns):

    p0_inputs = sint.Matrix(rows,columns)
    p0_inputs.input_from(0)

    p1_inputs = sint.Matrix(rows,columns)
    p1_inputs.input_from(1)

    p2_inputs = sint.Matrix(rows,columns)
    p2_inputs.input_from(2)
    #Large Array
    shamir_input = sint.Matrix((3*rows),columns)

    @for_range_parallel(3,[rows,columns])
    def hi(i,j):
    	shamir_input[i][j] = p0_inputs[i][j]
    	shamir_input[i+rows][j] = p1_inputs[i][j]
    	shamir_input[i+(rows*2)][j] = p2_inputs[i][j]
    return shamir_input

def first_entropy(CombinedInputs, shapeIndex,totalRows):
    entropy = sfix.MemValue(0)
    triangles = sint.MemValue(0)
    squares = sint.MemValue(0)
    @for_range_opt(totalRows)
    def f(i):
        #Load in value from InputArray
        compvar = CombinedInputs[i][shapeIndex]
		#sint(1) is the value for triangles in the dataset
        f = (compvar == sint(1))
        triangles.write(triangles+f)
        squares.write(squares+(sint(1)-f))

    x = sfix(sfix(triangles)/sfix(totalRows))
    y = sfix(squares)/sfix(totalRows)
    entropy.write((-x*(mpc_math.log2_fx(x)))+(-y*(mpc_math.log2_fx(y))))

    return entropy

#Slide 19
#This calculates the gain which is the Entropy of the shapes minus whatever entropy attribute we are comparing
def get_gain(EntroValue,unique_vales,Comparison_Entropy,value_tracking_array,range):
	sum_of_Entro = sfix.MemValue(0.0)
	@for_range_opt(unique_vales)
	def tr(i):
		sum_of_Entro.write(((value_tracking_array[i]/range)*EntroValue[i])+ sum_of_Entro)
	gain = Comparison_Entropy - sfix(sum_of_Entro)
	return gain

def attribute_gain(CombinedInputs,Comparison_Entropy,column_number,range):
	Entropy_Array = Array(3,sfix)
	value_tracking_array = Array(5,sfix)
	value_tracking_array.assign_all(0)
	lastint = sint(0)
	skip = 0
	shape_array = Array(3,sfix)
	shape_array.assign_all(0)

    #I am doing some cheating here, knowing that we have only 3 unique values for our dataset
    #I am just going to get track of them inidivually and hopefully it will be readable
	onevar = sint.MemValue(0)
	twovar = sint.MemValue(0)
	threevar = sint.MemValue(0)

    #Cheating again, here we are keeping track of one only shape of the at most 3 unique values
    #we will later find the amount of the other shape using subtraction
	oneshape = sint.MemValue(0)
	twoshape = sint.MemValue(0)
	threeshape = sint.MemValue(0)

	gain = sfix(0.0)
	unique_vales = sint.MemValue(1)
	@for_range_opt(range)
	def f(i):
		compvar = CombinedInputs[i][column_number]
		shape_value = CombinedInputs[i][3]
		lastint = (shape_value == sint(1))

        #Since we are only checking for upto 3 unique values we only need to compare upto 3 possibilities

		f = (compvar == sint(1))
		onevar.write(((onevar+1)*f)+  ((sint(1)-f)*onevar))
		oneshape.write(((oneshape+lastint)*f)+  ((sint(1)-f)*oneshape))
		f = (compvar == sint(2))
		twovar.write(((twovar+1)*f) +((sint(1)-f)*twovar))
		twoshape.write(((twoshape+lastint)*f) +((sint(1)-f)*twoshape))
		f = (compvar == sint(3))
		threevar.write(((threevar+1)*f)+((sint(1)-f)*threevar))
		threeshape.write(((threeshape+lastint)*f)+((sint(1)-f)*threeshape))

		f = (unique_vales < compvar)
		unique_vales.write((compvar*f)+(unique_vales*(sint(1)-f)))

        #This fixes a bug with the program
        #I don't understand but this fixes it
		if((sint(0) < sint(1)).reveal()):
			skip = 0



	value_tracking_array[0] = onevar
	value_tracking_array[1] = twovar
	value_tracking_array[2] = threevar

	shape_array[0] = oneshape
	shape_array[1] = twoshape
	shape_array[2] = threeshape

    #this calculates the entropy based on the 3 remaining attributes
    #since we only have 2 shapes to choose from, I am cheating again with partone and parttwo
    #
	@for_range_opt(unique_vales.reveal())
	def W(i):
		denom = value_tracking_array[i]
		top = shape_array[i]
		x = top/denom
		difference = denom-top
		y = difference/denom
		partone = (x*mpc_math.log2_fx(x))
		parttwo = (y*mpc_math.log2_fx(y))
		Entropy_Array[i] = (-partone)+(-parttwo)

	gain = get_gain(Entropy_Array,unique_vales.reveal(),Comparison_Entropy,value_tracking_array,range)
    #print_ln('Gain is %s',gain.reveal())
	return gain

#Combine all 3 parties inputs into 1 single array for ease of use
CombinedInputs = generateArray(rows,columns)
totalRows = rows*3

Shape_Entropy = sfix(0.0)
#calculate the Entropy of the Shape Attirbute
#3 is used at the second parameter because that is the column index for the shape attribute
Shape_Entropy = first_entropy(CombinedInputs,3,totalRows)
print_ln('Entropy of the Shape attribute is %s', Shape_Entropy.reveal())
print_ln()
print_ln()

gain_array = Array(3,sfix)
@for_range_opt(3)
def gainAll(i):
	gain_array[i]= attribute_gain(CombinedInputs,Shape_Entropy,i,totalRows)

print_ln("The Color attribute has a gain of %s", gain_array[0].reveal())
print_ln("The Outline attribute has a gain of %s", gain_array[1].reveal())
print_ln("The Dot attribute has a gain of %s", gain_array[2].reveal())
print_ln()
print_ln()

f = sint(-1)
largestGain = sfix.MemValue(0.0)
maxindex = sint.MemValue(0)
@for_range_opt(3)
def _(i):
	f = (largestGain < gain_array[i])
	maxindex.write((f*i)+ (maxindex*(sint(1)-f)))
	largestGain.write((gain_array[i]*f)+ (largestGain*(sint(1)-f)))
print_ln('largest gain index is %s which is %s',maxindex.reveal(),gain_array[maxindex.reveal()].reveal())
print_ln()
print_ln()
#For tree building our first layer has been determine from the attribute with the largest gain
#once we divide all inputs by color then we have to find the gain for outline and dot for each indivual color
#
color_Entropy = Array(3,sfix)
color_Entropy = get_Color_Entropy(CombinedInputs,maxindex.reveal(),totalRows)
print_ln()
print_ln()

get_Next_layer(CombinedInputs,color_Entropy,totalRows)
