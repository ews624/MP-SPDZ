import pandas as pd
import math
import numpy as np
import mpc_math



#sfix.set_precision(8,32)
#With above entro is .949219
#Actually answer is .94
#with it commented out the entro is now .940338


p0_inputs = sint.Matrix(14,4)
p0_inputs.input_from(0)

p1_inputs = sint.Matrix(14,4)
p1_inputs.input_from(1)

p2_inputs = sint.Matrix(14,4)
p2_inputs.input_from(2)


#print_ln('from p0 this should be 3 %s',p0_inputs[5][0].reveal())


def first_entropy(examples, count):
	total = sfix.MemValue(0)
	
	entropy = sfix.MemValue(0)
	temp = sint(1)
	two = sint(2)
	testing = sint(0)
	different_attri = Array(10,sfix)
	attri_count = sint.MemValue(0)
	different_attri.assign_all(0)
	x = sfix(0)
	array = Array(14,sint)

	@for_range_opt(14)
	def f(i):
		compvar = examples[i][count]
		different_attri[compvar.reveal()-1] =  different_attri[compvar.reveal()-1] +1

		if((attri_count < compvar).reveal()):
			attri_count.write(compvar.reveal())

		total.write(total+1)

	#print_ln('total is %s',total.reveal())
	#print_ln('attir count is %s',attri_count.reveal())

	@for_range_opt(attri_count.reveal())
	def W(i):
		testing = different_attri[i]
		#print_ln('%s',testing.reveal())
		x = testing/total
		#print_ln('x is %s',x.reveal())
		entropy.write(entropy -(x*(mpc_math.log2_fx(x))))

	return entropy

def first_shamir_entropy(p0,p1,p2, count):
	total = sfix.MemValue(0)
	
	entropy = sfix.MemValue(0)
	temp = sint(1)
	two = sint(2)
	testing = sint(0)
	different_attri = Array(10,sfix)
	attri_count = sint.MemValue(0)
	different_attri.assign_all(0)
	p1_attri = Array(10,sfix)
	p1_attri.assign_all(0)
	p2_attri = Array(10,sfix)
	p2_attri.assign_all(0)
	x = sfix(0)

	array = Array(14,sint)

	p0count = sfix.MemValue(0)


	@for_range_opt(14)
	def f(i):
		p0var = p0[i][count]
		different_attri[p0var.reveal()-1] =  different_attri[p0var.reveal()-1] +1
		
		p1var = p1[i][count]
		p1_attri[p1var.reveal()-1] =  p1_attri[p1var.reveal()-1] +1
		
		p2var = p2[i][count]
		p2_attri[p2var.reveal()-1] =  p2_attri[p2var.reveal()-1] +1
		
		if((attri_count < p0var).reveal()):
			attri_count.write(p0var.reveal())

		total.write(total+3)

	#print_ln('total is %s',total.reveal())
	#print_ln('attir count is %s',attri_count.reveal())

	@for_range_opt(attri_count.reveal())
	def W(i):
		testing = different_attri[i] + p1_attri[i] + p2_attri[i]
		#print_ln('%s',testing.reveal())
		x = testing/total
		#print_ln('x is %s',x.reveal())
		entropy.write(entropy -(x*(mpc_math.log2_fx(x))))

	return entropy

EntroArray = Array(4,sfix)
first_shamir_array = Array(4,sfix)
@for_range_opt(4)
def fl(i):
	EntroArray[i] = first_entropy(p0_inputs,i)
	print_ln('Normal Entropy is %s',EntroArray[i].reveal())
	first_shamir_array[i] = first_shamir_entropy(p0_inputs,p1_inputs,p2_inputs,i)
	print_ln('Shamir Entropy is %s',first_shamir_array[i].reveal())

print_ln('the last index in the array is %s', EntroArray[-1].reveal())

'''

def sec_entropy(examples,color_array,count):
	different_attri = Array(10,sfix)
	temp = sint(1)
	attri_count = sint.MemValue(1)
	different_attri.assign_all(0)
	x = sfix(0)
	array = Array(14,sint)
	shape_array = Array(10,sfix)
	shape_array.assign_all(0)
	@for_range_opt(14)
	def f(i):
		compvar = examples[i][count]
		lastvar = examples[i][3]
		different_attri[compvar.reveal()-1] =  different_attri[compvar.reveal()-1] +1
		
		if((lastvar ==temp).reveal()):
			shape_array[compvar.reveal()-1] = shape_array[compvar.reveal()-1] +1
		
		if((attri_count < compvar).reveal()):
			attri_count.write(compvar.reveal())
		
	#print_ln('There are %s 1s, %s 2s,and %s 3 in the %s column',different_attri[0].reveal(),different_attri[1].reveal(),different_attri[2].reveal(), count)
	
	#print_ln('attir count is %s',attri_count.reveal())

	return_Array = Array(5,sfix)

	@for_range_opt(attri_count.reveal())
	def W(i):
		denom = different_attri[i]
		#print_ln('%s',denom.reveal())
		color_array[i] = denom
		top = shape_array[i]
		#print_ln('shape array is %s',top.reveal())
		x = top/denom
		#print_ln('x is %s',x.reveal())
		
		rest = denom-top
		rest = rest/denom
		#print_ln('rest is %s',rest.reveal())
		partone = (x*mpc_math.log2_fx(x))
		#print_ln('partone is %s',partone.reveal())
		parttwo = (rest*mpc_math.log2_fx(rest))
		#print_ln('parttwo is %s',parttwo.reveal())
		return_Array[i] = (-partone)+(-parttwo)
	return return_Array

second_color_array = Array(3,sfix)
second_entro_array = sec_entropy(p0_inputs,second_color_array,0)
print_ln('Color count of green is %s',second_color_array[0].reveal())

total_rows = second_color_array[0] + second_color_array[1] + second_color_array[2]


#print_ln('Second Entropy is %s',sec_entropy(p0_inputs,0))


sum_of_Entro = ((second_color_array[0]/total_rows)*second_entro_array[0]) + ((second_color_array[1]/total_rows)*second_entro_array[1]) + ((second_color_array[2]/total_rows)*second_entro_array[2])

print_ln('the sum of the entros is %s',  sum_of_Entro.reveal())


gain = EntroArray[-1] - sum_of_Entro
print_ln('Gain for color is %s', gain.reveal())



second_array = Array(3,sfix)
outline_entro_array =  sec_entropy(p0_inputs,second_array,1)

sum_of_Entro = ((second_array[0]/total_rows)*outline_entro_array[0]) + ((second_array[1]/total_rows)*outline_entro_array[1])

gain = EntroArray[-1] - sum_of_Entro
print_ln('Gain for outline is %s', gain.reveal())


second_array.assign_all(0)
dot_entro_array = sec_entropy(p0_inputs,second_array,2)
sum_of_Entro = ((second_array[0]/total_rows)*dot_entro_array[0]) + ((second_array[1]/total_rows)*dot_entro_array[1])
gain = EntroArray[-1] - sum_of_Entro
print_ln('Gain for dot is %s', gain.reveal())
'''


